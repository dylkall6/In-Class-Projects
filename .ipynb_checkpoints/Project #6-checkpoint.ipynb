{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #6\n",
    "\n",
    "### Building Maps in geopandas\n",
    "In this lesson we will download COVID-19 data from data.world. We will normalize the data to compare spread between counties. Were we to simply plot the total number of cases or deaths by county, the results would be biased as counties with larger populations would likely have more cases and more deaths. We will observe how the spread developed across the country, starting in the northeast, eventually making its way to other regions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the COVID-19 data\n",
    "We will use two datasets. First, we will import a shapefile to use with geopandas, which we will later use to generate a county level map that tracks COVID-19. The shapefile is provide for you in the Github folder housing this post. You can also download shapefiles from the U.S. Census website. We will download Johns Hopkins's COVID-19 data from the Associated Press's account at data.world using their Python module. Follow these instructions to install the datadotworld module and access their API.\n",
    "\n",
    "> Datadotworld may be useful efficiently collecting data for class projects, so keep this libary in mind as you make plans for your project.\n",
    "\n",
    "First we will create the functions that download and import the data, then we will call these functions in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_datadir' from 'pyproj' (C:\\Users\\Dylan\\Code\\lib\\site-packages\\pyproj\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-47a1cfd8aecd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyproj\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_datadir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatadir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\lib\\site-packages\\geopandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptions\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeoseries\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeoSeries\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeodataframe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeoDataFrame\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpoints_from_xy\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\lib\\site-packages\\geopandas\\geoseries.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyproj\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCRS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseGeometry\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\lib\\site-packages\\pyproj\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyproj\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_datadir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m from pyproj._list import (  # noqa: F401\n\u001b[0;32m     52\u001b[0m     \u001b[0mget_angular_units_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_datadir' from 'pyproj' (C:\\Users\\Dylan\\Code\\lib\\site-packages\\pyproj\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import datetime\n",
    "from pyproj import _datadir, datadir\n",
    "\n",
    "import datadotworld as dw\n",
    "\n",
    "def import_covid_data(FIPS_name):\n",
    "    # Load COVID19 county data using datadotworld API\n",
    "    # Data provided by John Hopkins, file provided \n",
    "    # by Associated Press\n",
    "    dataset = dw.load_dataset(\n",
    "        \"associatedpress/johns-hopkins-coronavirus-case-tracker\",\n",
    "        auto_update = True)\n",
    "    \n",
    "    #the dataset includes multiple dataframes. We will only use #2\n",
    "    covid_data = dataset.dataframes[\n",
    "        \"2_cases_and_deaths_by_county_timeseries\"]\n",
    "    covid_data = covid_data[covid_data[FIPS_name] < 57000]\n",
    "    covid_data = covid_data[covid_data[FIPS_name] > 0]\n",
    "    # Transform FIPS codes into integers\n",
    "    covid_data[FIPS_name] = covid_data[FIPS_name].astype(int)\n",
    "    covid_data.set_index([FIPS_name, \"date\"], inplace = True)\n",
    "    \n",
    "    # Prepare a column for state abbreviations. we will draw these \n",
    "    # from state_dict\n",
    "    covid_data[\"state_abr\"] = \"\"\n",
    "    for state, abr in state_dict.items():\n",
    "        #.loc[row(s), col]\n",
    "        covid_data.loc[\n",
    "            covid_data[\"state\"] == state, \"state_abr\"] = abr\n",
    "    # save location name as Cass, ND \n",
    "    covid_data[\"Location\"] = covid_data[\"location_name\"] + \", \" +\\\n",
    "        covid_data[\"state_abr\"]\n",
    "    return covid_data\n",
    "\n",
    "def import_geo_data(filename, index_col = \"Date\", \n",
    "                    FIPS_name = \"FIPS\"):\n",
    "    # import county level shapefile\n",
    "    map_data = geopandas.read_file(filename = filename, \n",
    "                                  index_col = index_col)\n",
    "    map_data.rename(columns = {\"State\":\"state\"},\n",
    "                   inplace = True)\n",
    "    # Combine statefips and county fips to create a single fips value\n",
    "    # that identifies each particular county without referencing the\n",
    "    # state separately\n",
    "    map_data[FIPS_name] = map_data[\"STATEFP\"].astype(str) +\\\n",
    "        map_data[\"COUNTYFP\"].astype(str)\n",
    "    map_data[FIPS_name] = map_data[FIPS_name].astype(np.int64)\n",
    "    map_data.set_index(FIPS_name, inplace = True)\n",
    "    \n",
    "    return map_data\n",
    "\n",
    "state_dict = {\n",
    "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR', 'California': 'CA', 'Colorado': 'CO',\n",
    "    'Connecticut': 'CT', \n",
    "    'Delaware': 'DE', 'District of Columbia': 'DC', 'Florida': 'FL', \n",
    "    'Georgia': 'GA', 'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL',\n",
    "    'Indiana': 'IN', 'Iowa': 'IA','Kansas': 'KS', 'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD', \n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', \n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', \n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', \n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX',\n",
    "    'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA',\n",
    "    'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', \n",
    "    'Wyoming': 'WY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_name = \"fips_code\"\n",
    "# rename_FIPS matches map_data FIPS with COVID19 FIPS name\n",
    "covid_data = import_covid_data(FIPS_name = fips_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data = import_geo_data(\n",
    "    filename = \"countiesWithStatesAndPopulation.shp\",\n",
    "    index_col = \"Date\", FIPS_name= fips_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(map_data.loc[38017, \"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data.loc[38017, \"geometry\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot all of the data at once using df.plot(). However, we will want to specify map parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COVID19Map.py\n",
    "# . . .\n",
    "def create_covid_geo_dataframe(covid_data, map_data, dates):\n",
    "    # create geopandas dataframe with multiindex for date\n",
    "    # original geopandas dataframe had no dates, so copies of the df are \n",
    "    # stacked vertically, with a new copy for each date in the covid_data index\n",
    "    #(dates is a global)\n",
    "    i = 0\n",
    "    for date in dates:\n",
    "        # select county observations from each date in dates\n",
    "        df = covid_data[covid_data.index.get_level_values(\"date\")==date]\n",
    "        # use the fips_codes from the slice of covid_data to select counties\n",
    "        # from the map_data index,making sure that the map_data index matches\n",
    "        # the covid_data index\n",
    "        counties = df.index.get_level_values(\"fips_code\")\n",
    "        # call a slice of the geodataframe that includes the counties \n",
    "        # that are in covid_data\n",
    "        agg_df = map_data.loc[counties]\n",
    "        # each row should reflect the date so that it is aligned \n",
    "        # with covid_data\n",
    "        agg_df[\"date\"] = date\n",
    "        if i == 0:\n",
    "            # create the geodataframe, select coordinate system (.crs) to\n",
    "            # match map_data.crs\n",
    "            matching_gpd = geopandas.GeoDataFrame(agg_df, crs = map_data.crs)\n",
    "            i += 1\n",
    "        else:\n",
    "            # after initial geodataframe is created, stack a dataframe for\n",
    "            # each date in dates. Once completed, index of matching_gpd\n",
    "            # will match index of covid_data\n",
    "            matching_gpd = matching_gpd.append(agg_df, ignore_index = False)         \n",
    "    # Set mathcing_gpd index as[\"fips_code\", \"date\"], liked covid_data index\n",
    "    matching_gpd.reset_index(inplace=True)\n",
    "    matching_gpd.set_index([\"fips_code\",\"date\"], inplace = True)\n",
    "    # add each column from covid_data to mathcing_gpd\n",
    "    for key, val in covid_data.items():\n",
    "        matching_gpd[key] = val\n",
    "    return matching_gpd       \n",
    "\n",
    "# . . . to end of script . . .\n",
    "# dates will be used to create a geopandas DataFrame with multiindex \n",
    "dates = sorted(list(set(covid_data.index.get_level_values(\"date\"))))\n",
    "covid_data = create_covid_geo_dataframe(covid_data, map_data, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COVID19Map.py\n",
    "# . . .\n",
    "def create_new_vars(covid_data, moving_average_days):\n",
    "    # use a for loop that performs the same operations on data for cases and for deaths\n",
    "    for key in [\"cases\", \"deaths\"]:\n",
    "        # create a version of the key with the first letter of each word capitalized\n",
    "        cap_key = key.title()\n",
    "        covid_data[cap_key + \" per Million\"] = covid_data[\"cumulative_\" + key]\\\n",
    "            .div(covid_data[\"total_population\"]).mul(10 ** 6)\n",
    "        # generate daily data normalized per million population by taking the daily difference within each\n",
    "        # entity (covid_data.index.names[0]), dividing this value by population and multiplying that value\n",
    "        # by 1 million 10 ** 6\n",
    "        covid_data[\"Daily \" + cap_key + \" per Million\"] = \\\n",
    "            covid_data[\"cumulative_\" + key ].groupby(covid_data.index.names[0])\\\n",
    "            .diff(1).div(covid_data[\"total_population\"]).mul(10 ** 6)\n",
    "        # taking the rolling average; choice of number of days is passed as moving_average_days\n",
    "        covid_data[\"Daily \" + cap_key + \" per Million MA\"] = covid_data[\"Daily \" + \\\n",
    "                  cap_key + \" per Million\"].rolling(moving_average_days).mean()\n",
    "# . . .\n",
    "moving_average_days = 7\n",
    "create_new_vars(covid_data, moving_average_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#COVID19Map.py\n",
    "#. . . \n",
    "\n",
    "# only include observations within these boundaries\n",
    "# this will shrink the size of the map\n",
    "def select_data_within_bounds(data, minx, miny, maxx, maxy):\n",
    "    data = data[data.bounds[\"maxx\"] <= maxx]\n",
    "    data = data[data.bounds[\"maxy\"] <= maxy]\n",
    "    data = data[data.bounds[\"minx\"] >= minx]\n",
    "    data = data[data.bounds[\"miny\"] >= miny]\n",
    "    \n",
    "    return data\n",
    "\n",
    "# . . . to end of script\n",
    "# choose most recent date in data\n",
    "date = dates[-1]\n",
    "\n",
    "# choose map bounds\n",
    "if \"map_bounded\" not in locals():\n",
    "    minx = -127\n",
    "    miny = 23\n",
    "    maxx = -66\n",
    "    maxy = 48\n",
    "    covid_data = select_data_within_bounds(covid_data, minx, miny, maxx, maxy)\n",
    "    map_bounded = True\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(18,8),\n",
    "        subplot_kw = {'aspect': 'equal'})   \n",
    "plt.rcParams.update({\"font.size\": 30})\n",
    "plt.xticks(fontsize = 25)\n",
    "plt.yticks(fontsize = 25)\n",
    "key = \"Deaths per Million\"\n",
    "df = covid_data[covid_data.index.get_level_values(\"date\") == date]\n",
    "df.plot(ax=ax, cax = ax, column=key, linewidth=.5, \n",
    "             edgecolor='lightgrey')\n",
    "ax.set_title(str(date) + \"\\n\" + \"COVID-19 in the U.S.\", fontsize = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COVID19Map.py\n",
    "# . . . to end of script\n",
    "fig, ax = plt.subplots(figsize=(18,8),\n",
    "        subplot_kw = {'aspect': 'equal'})   \n",
    "plt.rcParams.update({\"font.size\": 30})\n",
    "plt.xticks(fontsize = 25)\n",
    "plt.yticks(fontsize = 25)\n",
    "key = \"Deaths per Million\"\n",
    "# change colors, divide into 4 distinct colors\n",
    "cmap = cm.get_cmap('Reds', 4)\n",
    "vmin = 1 \n",
    "vmax = df[key].max()\n",
    "\n",
    "norm = cm.colors.LogNorm(vmin=vmin, vmax =vmax)\n",
    "plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "df = covid_data[covid_data.index.get_level_values(\"date\") == date]\n",
    "df.plot(ax=ax, cax = ax, column=key, vmin=vmin ,vmax = vmax, \n",
    "             cmap = cmap, legend=False, linewidth=.5, edgecolor='lightgrey', \n",
    "             norm = norm)\n",
    "\n",
    "ax.set_title(str(date) + \"\\n\" + \"COVID-19 in the U.S.\", fontsize = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"Cases per Million\", \"Deaths per Million\", \n",
    "        \"Daily Cases per Million MA\", \"Daily Deaths per Million MA\"]\n",
    "for key in keys:\n",
    "    # identify whether or not to log values for color axis\n",
    "    # if daily rates, do not log. Only log totals.\n",
    "    log = False if \"Daily\" in key else True\n",
    "    fig, ax = plt.subplots(figsize=(18,8),\n",
    "        subplot_kw = {'aspect': 'equal'})   \n",
    "    plt.rcParams.update({\"font.size\": 30})\n",
    "    plt.xticks(fontsize = 25)\n",
    "    plt.yticks(fontsize = 25)\n",
    "    # this time we replace 0 values with 1\n",
    "    # so that these values show up as beige instead of as white\n",
    "    # when color axis is logged\n",
    "    df = covid_data[covid_data.index.get_level_values(\"date\")==date].replace(0,1)\n",
    "    # set range of colorbar\n",
    "    vmin = 1 if log else 0 \n",
    "    vmax = df[key].max()\n",
    "    # choose colormap\n",
    "    cmap = cm.get_cmap('Reds', 4)\n",
    "    # format colormap\n",
    "    if log:\n",
    "        norm = cm.colors.LogNorm(vmin=vmin, vmax =vmax)\n",
    "    else:\n",
    "        norm = cm.colors.Normalize(vmin = vmin, vmax = vmax)\n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    # empty array for the data range\n",
    "    sm._A = []\n",
    "    # prepare space for colorbar\n",
    "    divider = make_axes_locatable(ax)\n",
    "    size = \"5%\" \n",
    "    cax = divider.append_axes(\"right\", size = size, pad = 0.1)\n",
    "    # add colorbar to figure\n",
    "    cbar = fig.colorbar(sm, cax=cax, cmap = cmap)\n",
    "    cbar.ax.tick_params(labelsize=18)\n",
    "    vals = list(cbar.ax.get_yticks())\n",
    "    vals.append(vmax)\n",
    "\n",
    "    # format colorbar values as int\n",
    "    cbar.ax.set_yticklabels([int(x) for x in vals])\n",
    "    cbar.ax.set_ylabel(key, fontsize = 20)\n",
    "\n",
    "\n",
    "    df.plot(ax=ax, cax = cax, column=key, vmin=vmin ,vmax = vmax, \n",
    "                 cmap = cmap, legend=False, linewidth=.5, edgecolor='lightgrey', \n",
    "                 norm = norm)\n",
    "    ax.set_title(str(date)[:10] + \"\\n\" + \"COVID-19 in the U.S.\", fontsize = 30)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
